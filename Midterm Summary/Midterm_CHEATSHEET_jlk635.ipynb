{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUI2017 Midterm\n",
    "\n",
    "#### Cheat sheet for Jon Kastelan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# my usual imports and setups\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#imports downloader\n",
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "import scipy.stats\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopandas as gp\n",
    "from __future__ import print_function, division\n",
    "\n",
    "try:\n",
    "    import urllib2 as urllib\n",
    "except ImportError:\n",
    "    import urllib.request as urllib\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "GoogleAPIKEY = ''\n",
    "\n",
    "%pylab inline\n",
    "import json\n",
    "import os, shutil\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Read in file from website (e.g. txt, csv, xls, json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.irs.gov/pub/irs-soi/14zp33ny.xls      #get file from website, and puts into active directory\n",
    "!mv 14zp33ny.xls IRS_data_Income_by_ZIP.xls   #renames file from original file name (14zp33ny) to meaningful filename (IRS_data_Income_by_ZIP) \n",
    "os.system(\"mv IRS_data_Income_by_ZIP.xls \" + os.getenv(\"PUIDATA\")) #moves file to PUIDATA directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-10-25 13:50:51--  https://data.cityofnewyork.us/api/views/rgfe-8y2z/rows.csv\n",
      "Resolving data.cityofnewyork.us... 52.206.68.26\n",
      "Connecting to data.cityofnewyork.us|52.206.68.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: “rows.csv”\n",
      "\n",
      "    [  <=>                                  ] 4,433,512   17.0M/s   in 0.2s    \n",
      "\n",
      "Last-modified header invalid -- time-stamp ignored.\n",
      "2017-10-25 13:50:52 (17.0 MB/s) - “rows.csv” saved [4433512]\n",
      "\n",
      "mv rows.csv /home/cusp/jlk635/PUIdata\n"
     ]
    }
   ],
   "source": [
    "#download, move data to $PUIDATA, and read data in \n",
    "!wget https://data.cityofnewyork.us/api/views/rgfe-8y2z/rows.csv\n",
    "cmd = \"mv rows.csv \" + os.getenv(\"PUIDATA\")\n",
    "#the line below is to check that my string is formatted right. I should remove it to make the notebook delivery ready\n",
    "print (cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrg = gp.GeoDataFrame.from_csv(os.getenv(\"PUIDATA\") + \"/rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download zip file from website, move to PUIDATA and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/mn_mappluto_16v2.zip #get file from website\n",
    "os.system(\"mv mn_mappluto_16v2.zip \" + os.getenv(\"PUIDATA\")) #move to PUIDATA\n",
    "os.system(\"unzip \" + os.getenv(\"PUIDATA\") + \"/mn_mappluto_16v2.zip\" + \" -d \" + os.getenv(\"PUIDATA\") +\"/Manhattan\")\n",
    "# line above unzips the file (into a folder called Manhattan in PUIDATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create pd DataFrame from file read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df__ = pd.read_excel( path + \"/\" + \"filename\", sheetname='Sheet1', \\\n",
    "              header=0 (reference of head row (i.e. first list is 0)), skiprows=3 (skip rows at the top if needed), \\\n",
    "              index_col=0 (column ref to use as an index), skip_footer=16 (rows to cut from the bottom (if needed)))\n",
    "              \n",
    "#pd.read_excel(os.getenv(\"PUIDATA\") + \"/\" + \"IRS_data_Income_by_ZIP.xls\", sheetname='Sheet1', header=0, skiprows=3, index_col=0, skip_footer=16)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df__ = pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df__ = pd.read_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data processing and dataset build (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns not needed \n",
    "(notice first argument is a **list** of column names not needed, axis = refer to columns (0 would be rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df__.drop( ['Street Name', 'Borough', 'Source EUI(kBtu/ft2)', 'ENERGY STAR Score'] , axis=1, inplace=True)  \n",
    "#drops the columns not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Check columns of a dataframe\n",
    "df__.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3.dropna(subset=[\"Postcode\"],inplace=True) # drops rows with NaN in \"Postcode\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop whole columns which have any NaN values, set axis=1\n",
    "\n",
    "Drop rows which have NaN values in any columns, provide subset = ['column1', 'column2', .. 'columnN'] to check, and set axis = 0 (default)\n",
    "\n",
    "REMEMBER the inplace = True, once you've checked the dataset is what you want and you're happy with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrg.dropna?\n",
    "# nrg.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "#subset : array-like\n",
    " #   Labels along other axis to consider, e.g. if you are dropping rows\n",
    "#   these would be a list of columns to include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain unique values of array (and dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique?\n",
    "#Get the unique values for the zipcodes e.g.\n",
    "zipcs = np.unique(zipcs)   #Returns the sorted unique elements of an array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrg.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "#subset : column label or sequence of labels, optional\n",
    " #   Only consider certain columns for identifying duplicates, by default use all of the columns\n",
    "\n",
    "#keep : {‘first’, ‘last’, False}, default ‘first’\n",
    " #       first : Drop duplicates except for the first occurrence.\n",
    "#        last : Drop duplicates except for the last occurrence.\n",
    "   #     False : Drop all duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a dataframe using a for loop (not great practice, but if small.. do it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set columns of dataframe (and check the head has your column heading, but empty)\n",
    "\n",
    "columns=['zipcodes', 'income', 'N', 'Njoint', 'Ndeps']\n",
    "dfIncomeByZip = pd.DataFrame(columns=columns)\n",
    "\n",
    "print(dfIncomeByZip.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the dataframe using for loop (rows are: i)\n",
    "\n",
    "i=0\n",
    "\n",
    "for zip in zipcs:\n",
    "    \n",
    "    income = incomeByZip.loc[[zip]][\"Adjusted gross income (AGI) [3]\"].iloc[0]\n",
    "    N = incomeByZip.loc[[zip]][\"Total income\"].iloc[0]\n",
    "    Njoint = incomeByZip.loc[[zip]][\"Number of joint returns\"].iloc[0]\n",
    "    Ndeps = incomeByZip.loc[[zip]][\"Number of dependents\"].iloc[0]\n",
    "#incomePC = income / (N + Njoint + Ndeps)\n",
    "    dfIncomeByZip.loc[i]= [zip , income, N, Njoint, Ndeps]\n",
    "#dfIncomeByZip.head()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (row references, columns and keys (for dictionaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row index by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#index number\n",
    "\n",
    "df___.loc[ind][column] # ind is the row reference index e.g. 'could be a zipcode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sequential row number (starting at 0)\n",
    "\n",
    "df___.iloc[i][column] # i is the rownumber..  in sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example using $'enumerate'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Manhattan', 'Manhattan')\n",
      "('Queens', 'Queens')\n",
      "('Bronx', 'Bronx')\n"
     ]
    }
   ],
   "source": [
    "for i, ind in enumerate(nrg.index.values[:3]):\n",
    "    print(nrg.loc[ind][6], nrg.iloc[i][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting indexes (rows) where column satisfies some criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splicing & Broadcasting - preferred method\n",
    "bblnrgdataCut = bblnrgdata[(bblnrgdata.nrg > 1000) * (bblnrgdata.UnitsTotal>=10) * \n",
    "                           (bblnrgdata.UnitsTotal<1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain keys for dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address = \"https://maps.googleapis.com/maps/api/geocode/json?latlng=40.727103,-74.002971&key=AIzaSyC5BaF1S-f2vEFbZVMnt0aC8RLvFPJ-nCw\"\n",
    "        \n",
    "response = urllib.urlopen(address)\n",
    "read_data = response.read()\n",
    "addressdata = json.loads(read_data)\n",
    "\n",
    "##LINE FOR dictionary keys\n",
    "addressdata.keys() #obtain keys for the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of columns (e.g. to numeric, or to str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert to float\n",
    "\n",
    "nrg['Reported Property Floor Area (Building(s)) (ft²)'] = \\\n",
    "            pd.to_numeric(nrg['Reported Property Floor Area (Building(s)) (ft²)'], \n",
    "                          errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converts to Strings or integers\n",
    "\n",
    "total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)\n",
    "test3.Postcode.astype(int) ## postcode as int saves on memory (instead of a float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting data if dataset is large take a sampling of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df___ = df___.sample(20000, replace=False)  #takes random sample (size = 20,000) without replacement of df___ dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping / .groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMEMBER YOU NEED A FUNCTION AFTER\n",
    "\n",
    "\"test3.groupby(by=\"Borough\")\" \n",
    "\n",
    "i.e. you need a .mean(), or a .count(), or a .count()[\"BBL\"].hist(), or a .count()[\"BBL\"].plot(kind=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3.groupby(by=\"Borough\").mean() #find the mean of columns (where sensible to calculate a mean) \n",
    "                                   #by Borough which are not NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3.groupby(by=\"Postcode\").count() #counts number of entries by zipcode which are not NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3.groupby(by=\"Borough\").sum() #find the sum of columns (where sensible to calculate a sum) \n",
    "                                  #by Borough which are not NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#notice the index is the groupby category. Often it may be useful to have that as a column instead:\n",
    "test3.groupby(by = \"Borough\", as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JK to review this code  (pulled from fed solutions), and put a line and a legend in there also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I find the easiest way to use the formula package is to use a dataframe \n",
    "#with the quantities that are not linear already calculated\n",
    "\n",
    "bblnrgdataCut['logNrg']  = np.log10(bblnrgdataCut.nrg)\n",
    "bblnrgdataCut['logUnits']  = np.log10(bblnrgdataCut.UnitsTotal)\n",
    "\n",
    "X = np.linspace(bblnrgdataCut['logUnits'].min(), bblnrgdataCut['logUnits'].max(), 1000)\n",
    "curvemodel = smf.ols(formula = 'logNrg ~ logUnits + I(logUnits**2)', \n",
    "                          data = bblnrgdataCut).fit()\n",
    "pl.figure(figsize=(16,14))\n",
    "pl.scatter(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg))\n",
    "plot(X, curvemodel.predict(exog = dict(logUnits = X)), 'k')\n",
    "xl = pl.xlabel(\"log10 Number of Units in Building\", fontsize=20)\n",
    "yl = pl.ylabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "curvemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests - REMEMBER TO STATE YOUR ALPHA apriori $\\alpha$ = 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests on samples/population parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Z-test / t-test - sample mean, or proportion equal to.. x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tests for correlation: Pearson, Spearman rank - \n",
    "# both test null hypothesis that correlation = 0 (i.e. samples are 'uncorrelated') \n",
    "#Spearman uses rank statistics so not influenced by magnitude of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KS tests for comparing two samples - are they similar  (and AD for multi samples, assumed underlying Gaussianity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests on distribution #goodnessoffit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS test - one sample comes from underlying distribution (e.g. 'norm', 'pois' etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pearsons chi-square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AD  SPICY.STATS.ANDERSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KL - information entropy measure. Not a test, but if the functions have entropy converging to zero, they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# likelihood ratio test: LLR - the business of models.. for nested, check if my simple model is equivalent to the\n",
    "# the complicated model. if they are the same, use the simple model (the additional 'complicated' term isn't adding\n",
    "# anything... apart from confusion, so remove it).\n",
    "\n",
    "alpha = 0.05\n",
    "print (\"LR : \", -2 * (linmodel_1.llf - (curvemodel.llf)))\n",
    "print (\"LR from statsmodels:\", curvemodel.compare_lr_test(linmodel_1))\n",
    "LR = curvemodel.compare_lr_test(linmodel_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Standard mods for the charts if needed\n",
    "\n",
    "fig = pl.figure(figsize=(15,15))    # for fig size\n",
    "ax = fig.add_subplot(111)  # for subplot/s\n",
    "\n",
    "ax.tick_params(axis='both',labelsize=16)\n",
    "pl.title(\"Figure ##: The quick brown fox jumped over the lazy dog \\n\", fontsize=20)\n",
    "ax.set_ylabel(\"y: [desc]\", fontsize=18)\n",
    "ax.set_xlabel(\": [desc]\", fontsize=18)\n",
    "ax.set_ylim()#0,100)\n",
    "ax.set_xlim()#0,100)\n",
    "ax.grid();   # for the gridlines (if you want them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter = ax.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Geocoding (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This piece of code takes latitude (lat) and longitude (lon) coordinates to obtain a ZIP code from Google API\n",
    "\n",
    "coordref = cb2015LatLon['start station latitude']\n",
    "a = 0\n",
    "\n",
    "for i in coordref:\n",
    "    \n",
    "    lat = cb2015LatLon['start station latitude'][a]\n",
    "    lon = cb2015LatLon['start station longitude'][a]\n",
    "    \n",
    "    address = \"https://maps.googleapis.com/maps/api/geocode/json?latlng=\" + str(lat) + \",\" + str(lon) + \"&key=\" + key\n",
    "\n",
    "    response = urllib.urlopen(address)\n",
    "    read_data = response.read()\n",
    "    addressdata = json.loads(read_data)\n",
    "    \n",
    "    zipcb = str(addressdata[\"results\"][0]['address_components'][-1]['long_name'])\n",
    "    \n",
    "    cb2015LatLon['ZIP_code_cb'][a] = zipcb\n",
    "#    print(a, lat, lon, zipcb ) # for debugging - see where the code fails.. if it fails?\n",
    "    a = a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
