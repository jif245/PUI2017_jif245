{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paquetes que pueden ser de utilidad para examen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/anaconda/root/envs/PUI2016_Python2/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['Polygon']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import os\n",
    "import json\n",
    "import statsmodels as st\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import normal\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar bases de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://...csv\") # Recordar hacerlo siempre asegurando reproducibilidad.\n",
    "\n",
    "#Para json, el de abajo. También es importante asegurar reproducibilidad.\n",
    "json_data=open('/home/cusp/jss895/PUI2017/PUIdata/vehicle-monitoring.json').read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "#Podemos usar para enviar a PUIdata. SOLO CUANDO ESTEMOS TRABAJANDO EN COMPUTE!!!! \n",
    "os.chdir(os.environ.get(\"PUIDATA\"))\n",
    "!curl -O \"https://s3.amazonaws.com/tripdata/JC-201707-citibike-tripdata.csv.zip\"\n",
    "\n",
    "#Después usamos los siguientes comandos para asegurarnos que este guardada donde corresponde\n",
    "!pwd\n",
    "!ls\n",
    "\n",
    "#Una vez descargada la base de datos en la carpeta correcta, la unzippiamos:\n",
    "os.system('unzip ' + PUIdata + '/nyc_pluto_16v2%20.zip -d ' + PUIdata)\n",
    "\n",
    "#Así traemos los datos a dónde estamos trabajando\n",
    "data = pd.read_csv(PUIdata + '/BORO_zip_files_csv/MN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipular bases de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar columnas, filas y NaN. También convertir valores extraños en NaN. Finalmente funciones para crear nuevas columnas, formas para hacer merge y también para concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base de datos que contiene solo las columnas deseadas. Podría crearse nuevo DataFrame \n",
    "data = data[['BBL',\"DOF Number of Buildings\"]] \n",
    "\n",
    "#Crear base de datos nueva basada en condicionales.\n",
    "df = data[data[\"tripduration\"]<5000]\n",
    "df1 = df[df[\"gender\"]==\"Male\"]\n",
    "\n",
    "# Así droppiamos filas.\n",
    "data.drop(['Cochice', 'Pima'])\n",
    "\n",
    "#Así renombramos las columnas.\n",
    "data.rename(columns = {'Juanito Sokoloff':\"Juan\"}, inplace = True)\n",
    "\n",
    "# Así quitamos los valores que tienen NaN\n",
    "data = data.dropna()\n",
    "\n",
    "#Un drop más sofisticado, que toma cuales datos queremos quitar\n",
    "#Este sirve para eliminar outliers por ejemplo\n",
    "datacut = data[(df.UnitsTotal >= 10) & (df.UnitsTotal < 1000) & (df.EnergyCons > 1000)]\n",
    "\n",
    "# Así convertimos todos los valores númericos en floats y los valores extraños en NaN.\n",
    "data = data.apply(lambda x: pd.to_numeric(x, errors = \"coerce\"))\n",
    "\n",
    "#Así convertimos una variable en float, suponiendo que no tiene valores raros.\n",
    "data[\"nombrevariable\"] = data[\"nombrevariable\"].astype(float)\n",
    "\n",
    "#Así le damos nuevos valores a los que ya estaban en una columna,por ejemplo \"Female\" por 2.\n",
    "data.gender = data.gender.replace(2, \"Female\")\n",
    "\n",
    "# Merge basados en una columna que tiene el mismo nombre en ambas bases de datos.\n",
    "df = pd.merge(data, nrg, on=\"BBL\")\n",
    "\n",
    "#Merge utilizando columnas con mismo significado pero diferente nombre\n",
    "data = pd.merge(df, df1, right_on=\"Country Name\", left_on=\"Country\")\n",
    "\n",
    "#TENER CUIDADO SI QUEREMOS HACER UN INNER O UN OUTER MERGE.\n",
    "\n",
    "#Concatenate hacia abajo. Es decir poniendo una base de datos abajo de la otra.\n",
    "df1.columns = df.columns\n",
    "data = pd.concat([df, df1])\n",
    "\n",
    "#Concatenar de modo horizontal, es decir agregando una nueva columna a la base de datos.\n",
    "data = pd.concat([time311, timeNYPD], axis = 1, join = \"outer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear nuevas columnas y manipulación de datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Así creamos columnas nuevas con operaciones matemáticas.\n",
    "data['areatotal'] = data[\"areacuarto\"] + data[\"areasala\"] \n",
    "\n",
    "#Convertir columnas en datetime\n",
    "data['Created Date'] = pd.to_datetime(data['Created Date'])\n",
    "\n",
    "#Como utlizar solo una parte del datetime (En este caso conteo de la hora para hacer análisis)\n",
    "time311 = df.groupby(df5[\"Created Date\"].dt.hour).count()\n",
    "\n",
    "# Así creamos la columna time solo con la parte de la hora, sin la fecha.\n",
    "df['time'] = df['starttime'].apply(lambda x : pd.to_datetime(x).time())\n",
    "\n",
    "# Generar función para crear nueva columna. Ejemplo uno datetime. Ejemplo para locación\n",
    "def time_checker(t):\n",
    "    if t > nightstart:\n",
    "        return 'Night Rider'\n",
    "    if t < nightend:\n",
    "        return 'Night Rider'\n",
    "    else:\n",
    "        return 'Day Rider'\n",
    "\n",
    "df['typee'] = df['time'].apply(lambda x: time_checker(x))\n",
    "\n",
    "\n",
    "def borough(xy):\n",
    "    x,y = xy\n",
    "    if (x>40.698215)&(y<-73.970755):\n",
    "        return \"Manhattan\"        \n",
    "    else:\n",
    "        return \"Brooklyn\"\n",
    "    \n",
    "data[\"borough\"] = data[[\"start station latitude\",\"start station longitude\"]].apply(borough, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Descripción básica de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para ver las primeras filas de la base de datos\n",
    "data.head()\n",
    "\n",
    "# Para ver todas las columnas (variables)\n",
    "data.columns\n",
    "\n",
    "# Para ver la forma\n",
    "data.shape\n",
    "\n",
    "# Para una breve descripción de media, desviación estandar, mínimo, máximo, etc.\n",
    "data.describe()\n",
    "\n",
    "#También se pueden conseguir por separado.\n",
    "data[\"LotArea\"].std()\n",
    "data[\"LotArea\"].mean()\n",
    "\n",
    "#Usualmente esto se acompaña de un scatterplot, sección PLOTTING.\n",
    "\n",
    "#Hacer la media para objetos dentro de una columna\n",
    "data.groubby(by = \"Borough\").mean \n",
    "\n",
    "#Así contamos el número observacion\n",
    "data.groupby(by = \"Borough\").count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting.\n",
    "\n",
    "###  Debajo de cada gráfico hay que incluir un caption describiendo que quiere decir el gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Settear el tamaño de la figura. Si se usa para la primera queda default para las demás\n",
    "fig = pl.figure(figsize(8,8)) \n",
    "\n",
    "# Hacer subplots\n",
    "ax = fig.add_subplot(221) # Cuantos verticalmenta, Cuántos horizontalmente, Posición.\n",
    "ax1 = fig.add_subplot(222)\n",
    "ax2 = fig.add_subplot(223)\n",
    "ax3 = fig.add_subplot(224)\n",
    "\n",
    "# Scatter plot\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(df.EnergyCons, df.UnitsTotal, '.', alpha=0.5)\n",
    "ax.set_xlim(1000,1e8)\n",
    "ax.set_ylim(0,1000)\n",
    "ax.set_title('Total Number of Units against Total Energy Consumption per BBL')\n",
    "ax.set_xlabel('Energy Consumption (kBtu)')\n",
    "ax.set_ylabel('Number of Units per BBL');\n",
    "\n",
    "#Histogramas. En este ejemplo hay varios histogramas en una sola gráfica, podríamos tomar uno solo.\n",
    "#Es una buena herramienta para ver la forma de una distribución (Debe ser comprobada por tests estadísticos)\n",
    "hist(df1.tripduration, bins = 20, color = \"Grey\", label = \"Total trips\")\n",
    "hist(df2.tripduration, bins = 20, label = \"Male\")\n",
    "hist(df3.tripduration, bins = 20, color=\"red\", label = \"Female\")\n",
    "hist(df4.tripduration, bins = 20, color=\"green\", label = \"Unknown\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Trip Duration in seconds\", fontsize=12)\n",
    "plt.ylabel(\"Amount of trips\", fontsize=12)\n",
    "plt.title(\"Trip Duration Histogram by gender\", weight='bold', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# Bar plot con nombres en las variables que corresponden a nombres en una columna.\n",
    "# Podemos olvidar la primera parte y abajo va a gráficar basado en números.\n",
    "N = len(data[\"Guns/100 inhabitants\"])\n",
    "x = range(N)\n",
    "labels = [data[\"Country\"][0], data[\"Country\"][1], data[\"Country\"][2], data[\"Country\"][3], data[\"Country\"][4], data[\"Country\"][5], data[\"Country\"][6], data[\"Country\"][7], data[\"Country\"][8], data[\"Country\"][9], data[\"Country\"][10], data[\"Country\"][11], data[\"Country\"][12], data[\"Country\"][13], data[\"Country\"][14], data[\"Country\"][15], data[\"Country\"][16], data[\"Country\"][17], data[\"Country\"][18], data[\"Country\"][19], data[\"Country\"][20], data[\"Country\"][21]]\n",
    "\n",
    "plt.xticks(x, labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(x, data[\"Guns/100 inhabitants\"], align=\"center\")\n",
    "plt.xlabel(\"Country\", fontsize=12)\n",
    "plt.ylabel(\"Guns per 100 inhabitants\", fontsize=12)\n",
    "plt.title(\"Guns per 100 inhabitants by country\", weight='bold', fontsize=14)\n",
    "\n",
    "#Hacer plot con línea fitteada e intervalos de confianza (MANERA FÁCIL)\n",
    "sns.regplot(\"FirearmsPerPerson\", \"MassShootPerPerson\", data = data)\n",
    "\n",
    "# Hacer scatterplots con barras de errores (en este caso error = raíz cuadrada de la observación)\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter (data[\"Average total all civilian firearms\"]/1e6, data[\"Number of mass shootings\"],color=col)\n",
    "ax.errorbar(data[\"Average total all civilian firearms\"]/1e6,data[\"Number of mass shootings\"], xerr= np.sqrt(data[\"Average total all civilian firearms\"]/1e6) ,\n",
    "           yerr = np.sqrt(data[\"Number of mass shootings\"] * 1.0), fmt = '.',color=\"black\", alpha=0.3)\n",
    "ax.set_ylabel('Number of mass shootings')\n",
    "ax.set_xlabel(\"Civilian firearms (in millions)\")\n",
    "ax.set_ylim()\n",
    "pl.show()\n",
    "\n",
    "#Así fitteamos una Poisson\n",
    "x = np.arange(poisson.ppf(0.01, k), poisson.ppf(0.99, k))\n",
    "plt.plot(x, poisson.pmf(x, k), 'bo', ms=8, label='poisson pmf')\n",
    "plt.vlines(x, 0, poisson.pmf(x, k), colors='orange', lw=5, alpha=0.5)\n",
    "\n",
    "#Fittear una normal\n",
    "data=random.randn(1000000)\n",
    "mu, std = norm.fit(data)\n",
    "x = np.linspace(-3,3, 100)\n",
    "p = norm.pdf(x, 0, 1)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "#Scatter Matrix\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix (data, s=300, figsize=(16, 16));\n",
    "scatter_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting después de hacer modelos, básicamente para fittear líneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Una vez hechos los modelos podemos usar este codigo para hacer las líneas de ajuste\n",
    "plt.plot(x1, l1, '.')\n",
    "plt.plot(x1, linmodel1.fittedvalues, \"-\", color = \"r\")\n",
    "plt.xlabel(\"Country\", fontsize=12)\n",
    "plt.ylabel(\"Guns per 100 inhabitants\", fontsize=12)\n",
    "plt.title(\"Guns per 100 inhabitants by country\", weight='bold', fontsize=14)\n",
    "\n",
    "#Para modelo cuadrático\n",
    "pl.plot(x1, l1, '.')\n",
    "pl.plot(sort(x1), sort(model2.fittedvalues), \"-\", color = \"r\")\n",
    "plt.xlabel(\"Country\", fontsize=12)\n",
    "plt.ylabel(\"Guns per 100 inhabitants\", fontsize=12)\n",
    "plt.title(\"Guns per 100 inhabitants by country\", weight='bold', fontsize=14)\n",
    "\n",
    "#Para hacer plot de influencia\n",
    "statsmodels.graphics.regressionplots.influence_plot(model, alpha  = 0.05, criterion=\"cooks\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras formas de hacerlo, por sí las anteriores no funcionan (esta con logaritmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = lmLog.params[1]\n",
    "w2 = lmLog.params[0] \n",
    "\n",
    "df.loc[:,\"predLog\"]=b1*np.log(df[\"LotArea\"])+b2\n",
    "\n",
    "plt.scatter(np.log(df[\"LotArea\"]), np.log(df[\"AssessTot\"]))\n",
    "plt.plot(np.log(df[\"LotArea\"]), df.predLog, c=\"k\")\n",
    "plt.xlabel(\"LogLotArea\")\n",
    "plt.ylabel(\"LogAssessTot\")\n",
    "plt.title(\"Log-log regression between LotArea and AssessTot\", weight='bold', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para hacer modelo líneal con una sola variable.\n",
    "lm=smf.ols('AssessTot~LotArea',data=df).fit()\n",
    "lm.summary()\n",
    "\n",
    "# Mismo modelo líneal sin intercepto.\n",
    "lm1 = smf.ols(\"AssessTot~LotArea + 0\", data = df).fit()\n",
    "lm1.summary()\n",
    "\n",
    "# Para hacer modelo cuadrático\n",
    "sm = smf.ols(formula='y ~ x2 + x', data=df).fit()\n",
    "sm.summary()\n",
    "\n",
    "# Modelo WLS con errores wighted.\n",
    "model1 = sm.regression.linear_model.WLS(data[\"MassShootPerPerson\"], data[\"FirearmsPerPerson\"], 1/abs(model.resid)).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests Estadísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DIFFERENCE BETWEEN SAMPLES\n",
    "\n",
    "#Pearson\n",
    "scipy.stats.pearsonr(data[\"tripduration\"], data [\"dayornight\"])\n",
    "\n",
    "#Spearman\n",
    "scipy.stats.spearmanr(data[\"tripduration\"], data [\"dayornight\"])\n",
    "\n",
    "#K-S para dos muestras\n",
    "scipy.stats.ks_2samp(data[(data[\"dayornight\"] == 0)][\"tripduration\"],data[(data[\"dayornight\"] == 1)][\"tripduration\"])\n",
    "\n",
    "#Estadístico Z\n",
    "scipy.stats.zscore(data[\"cualquiercolumna\"])\n",
    "\n",
    "#Estadístico T\n",
    "scipy.stats.ttest_ind(a, b, axis=0, equal_var=True)\n",
    "\n",
    "# COMPARANDO ENTRE MUESTRAS\n",
    "\n",
    "#K-S para una muestra\n",
    "scipy.stats.kstest(data[\"tripduration\"], poisson, N=3309471)\n",
    "scipy.stats.kstest(dist_p,'norm')\n",
    "\n",
    "#K-S para dos muestras\n",
    "scipy.stats.ks_2samp(data[(data[\"dayornight\"] == 0)][\"tripduration\"],data[(data[\"dayornight\"] == 1)][\"tripduration\"])\n",
    "\n",
    "#Anderson Darling\n",
    "scipy.stats.anderson(dist_p, dist='norm')\n",
    "\n",
    "\n",
    "# GOODNESS OF FIT\n",
    "\n",
    "#LR\n",
    "-2 * (-linmodel.llf - (-seconddegreemodel.llf)))\n",
    "seconddegreemodel.compare_lr_test(linmodel))\n",
    "\n",
    "#ChiCuadrado\n",
    "def chi2(data, model, errors = None):\n",
    "    '''Calculates the chi sq given data, model and errors\n",
    "    Arguments:\n",
    "    data: series of datapoints (endogenous variable)\n",
    "    model: series of predicted values corresponding to the observed data\n",
    "    errors: serie of errors (optional). \n",
    "    If errors are not passes all errors are set to 1\n",
    "    '''\n",
    "    if errors is None:\n",
    "        errors = np.ones_like(data)\n",
    "    if data.shape == model.shape and data.shape == errors.shape:\n",
    "        return (((data - model)**2) / errors**2).sum()\n",
    "    else: \n",
    "        print ('''ERROR:\n",
    "must pass arrays of identical dimension for data, model and (optional) error)''')\n",
    "    return -1\n",
    "\n",
    "## Assume that there is error in the reported energy. \n",
    "## but that is the product of two measured qusntities, each of which will have errors. \n",
    "## The minimum error is the squareroot of the value\n",
    "\n",
    "#errors on the measured quantities\n",
    "errorsnrg = np.sqrt((bblnrgdataCut['Reported Property Floor Area'])**2 +\\\n",
    "                (bblnrgdataCut['Site EUI(kBtu/ft2)'])**2)\n",
    "\n",
    "# better WOULD BE to calculate each error and add in quadrature: sqrt(1/A + 1/B) which becomes\n",
    "#errorsnrg = np.sqrt(1.0 / bblnrgdataCut['Reported Property Floor Area'] + 1.0 / bblnrgdataCut['Site EUI(kBtu/ft2)'])\n",
    "#but this leads to insane error values (insanely small)\n",
    "\n",
    "## Assume count statistics in the number of units as well\n",
    "errorsunits = np.sqrt(bblnrgdataCut.UnitsTotal)\n",
    "\n",
    "\n",
    "errorsInLogNrg = np.abs(errorsnrg / bblnrgdataCut.nrg / np.log(10))\n",
    "errorsInLogUnits = np.abs(errorsunits / bblnrgdataCut.UnitsTotal / np.log(10))\n",
    "\n",
    "bblnrgdataCut['errorsnrg'] = errorsInLogNrg\n",
    "bblnrgdataCut['errorsunits'] = errorsInLogUnits\n",
    "\n",
    "dof = min(len(bblnrgdataCut.UnitsTotal) - np.isnan(bblnrgdataCut.UnitsTotal).sum(), \n",
    "         len(bblnrgdataCut.nrg) - np.isnan(bblnrgdataCut.nrg).sum()) - 2\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
